## 운전자 졸음 감지 시스템 개발 프로젝트 최종 보고서

### 1. 프로젝트 소개

본 프로젝트는 딥러닝 기술을 활용하여 운전자의 하품 여부 및 눈 감김 상태를 실시간으로 감지하고, 이를 통해 졸음 가능성을 판단하는 저비용 개인 맞춤형 시스템을 구축하는 것을 목표로 합니다. 기존 시스템의 고비용 생체 센서 의존성 및 개인차 미반영 문제를 해결한다.

### 2. 주제 관련 배경 및 용어 정리

* **컴퓨터 비전(Computer Vision):** 카메라를 통해 얻은 영상 데이터에서 사람의 얼굴, 눈, 입 등의 특징을 추출하고 분석하는 기술입니다.
* **얼굴 랜드마크(Facial Landmarks):** 얼굴의 특정 지점(눈, 코, 입 등)을 나타내는 좌표로, 눈 감김 및 하품 여부 판단에 활용됩니다. `dlib` 라이브러리가 주로 사용됩니다.
* **눈 감김 비율 (Eye Aspect Ratio, EAR):** 눈 주변 랜드마크 간의 거리 비율을 계산하여 눈이 얼마나 감겼는지를 나타내는 지표입니다. EAR 값이 특정 임계값 이하로 떨어지면 눈 감김(깜빡임, 졸음)으로 판단합니다.
    * `EAR = (‖P2 − P6‖ + ‖P3 − P5‖) / (2 ‖P1 − P4‖)` (P1-P6은 눈 랜드마크 2D 좌표)
* **입 벌림 비율 (Mouth Aspect Ratio, MAR):** 입 주변 랜드마크 간의 거리 비율을 계산하여 하품 여부를 판단하는 지표입니다.
    * MAR은 상순과 하순 사이의 평균 수직 거리를 입의 수평 거리로 나눈 값입니다.

### 3. 데이터셋 소개

졸음 감지 시스템 학습을 위해 다음과 같은 공개 데이터셋을 활용할 수 있습니다:

* **눈 상태 분류 (Open/Closed Eye):**
    * **Eyes Dataset (Kaggle):** 눈 이미지 데이터를 포함합니다.
    * **MRL Eye Dataset (Kaggle):** 다양한 조건의 눈 이미지 데이터를 제공합니다.
* **하품 감지 (Yawn/No Yawn):**
    * **Yawning Dataset (Kaggle):** 하품 및 비하품 얼굴 이미지를 포함합니다.
    * **YawDD (Yawning Detection Dataset):** 운전자들의 하품 및 비하품 영상 데이터셋으로, 실제 및 다양한 조명 조건에서 촬영되었습니다. '연기된 하품'이 포함될 수 있다는 점을 고려해야 합니다.
* **포괄적 졸음 감지:**
    * **UTA-RLDD (University of Texas at Arlington Real-Life Drowsiness Dataset):** 가장 큰 실제 졸음 감지 데이터셋 중 하나로, 졸음 상태(주의, 가벼운 졸음, 심한 졸음)가 라벨링된 시뮬레이션 운전 영상 30시간을 포함합니다.

### 4. 전처리 과정

1.  **얼굴 및 랜드마크 감지:** `OpenCV`와 `dlib` 라이브러리를 사용하여 영상 스트림에서 운전자의 얼굴을 감지하고, 이어서 68개 또는 81개의 얼굴 랜드마크를 추출합니다. 특히, `Haar Cascade Classifier`를 활용하여 얼굴과 눈 영역을 빠르게 식별할 수 있습니다.
2.  **관심 영역(ROI) 추출:** 감지된 얼굴 랜드마크를 기반으로 눈과 입 영역의 ROI를 추출합니다.
3.  **EAR 및 MAR 계산:** 추출된 눈 및 입 랜드마크 좌표를 이용하여 실시간으로 EAR 및 MAR 값을 계산합니다.
4.  **데이터 증강(Data Augmentation):** 데이터의 다양성을 높이고 모델의 일반화 성능을 향상시키기 위해 훈련 이미지에 대해 회전, 확대/축소, 좌우 반전 등 기하학적 변환을 적용합니다.
5.  **정규화 및 크기 조정:** 딥러닝 모델의 입력으로 사용하기 위해 이미지 픽셀 값을 정규화하고, 모델이 요구하는 입력 크기(예: 145x145 픽셀)로 조정합니다.

### 5. 모델 구조

* **Depthwise Separable Convolution:**  파라미터 수와 연산량을 크게 줄여 리소스 제약이 있는 환경(예: 임베디드 시스템, Colab)에 매우 효율적입니다. 90% 이상의 높은 정확도를 유지하면서 실시간 처리가 가능하여 졸음 감지에 매우 유리합니다.
* **YOLO (You Only Look Once):** YOLOv5 또는 YOLOv8과 같은 버전은 실시간 객체 탐지에 최적화되어 있어, 눈 감김 및 하품 객체를 동시에 탐지하고 분류하는 데 효과적입니다. Colab 환경에서 구현 및 훈련을 위한 많은 튜토리얼이 존재하여 초보자에게 적합합니다.
* **CNN (Convolutional Neural Network) 기반 분류 모델:**
      * **구조:** 여러 개의 컨볼루션 레이어, 활성화 함수(ReLU), 풀링 레이어(Max Pooling), 특징 융합(Feature Fusion, 눈/입 특징 결합), 완전 연결 레이어(Fully Connected Layers), 드롭아웃 레이어(과적합 방지), 소프트맥스(Softmax) 출력 레이어로 구성될 수 있습니다.
      * **특징:** 눈 상태(감김/열림)와 하품 여부(하품/하품 아님)를 분류하는 데 사용됩니다. VGG16, ResNet50과 같은 사전 학습된 모델을 전이 학습에 활용할 수도 있으나, MobileNet에 비해 모델 크기가 크고 연산량이 많을 수 있습니다.

### 6. 레퍼런스 개선점 

기존 졸음 감지 시스템의 **개인차 미반영** 문제를 해결하고 개인 맞춤형 시스템을 구현하기 위한 핵심 전략은 다음과 같습니다.

* **개인 맞춤형 임계값 설정:**
    * 초기 시스템 구동 시 5~10분간의 '캘리브레이션(Calibration)' 기간을 두어 운전자 개인의 평소 눈 깜빡임 빈도, 눈 감김 깊이, 입 벌림 정도 등에 대한 기준선(baseline)을 학습합니다.
    * 이 기준선을 바탕으로 EAR 및 MAR의 졸음 판단 임계값을 동적으로 조정하여 오탐지 및 미탐지를 줄입니다.
* **전이 학습 (Transfer Learning) 및 온라인 미세 조정 (Online Personalized Fine-Tuning, OPFT):**
    * 대규모 공개 데이터셋으로 사전 학습된 모델(예: MobileNet)을 기반으로 합니다.
    * 실제 운전 환경에서 운전자 개인의 데이터(초기 캘리브레이션 또는 지속적인 모니터링 중 수집된 데이터)를 사용하여 모델의 특정 레이어를 미세 조정(fine-tuning)합니다. 이를 통해 모델이 특정 운전자의 미묘한 졸음 징후에 더 민감하게 반응하도록 맞춤화할 수 있습니다.
    * 이는 모델이 새로운 운전자에게 빠르게 적응하고, 시간이 지남에 따라 운전자의 행동 변화에 대응할 수 있도록 합니다.

### 7. 프로젝트 결과 (성능 평가 및 지표)

프로젝트 결과는 정확도, 정밀도, 재현율, F1-score 등을 이용해 모델의 성능과 실시간 처리 능력을 평가합니다.. 

* **주요 평가 지표:**
    * **정확도 (Accuracy):** 졸음/비졸음 상태를 올바르게 분류하는 비율. (참고: MobileNet은 약 92.75%의 정확도를 보였습니다.)
    * **정밀도 (Precision):** 졸음으로 예측한 것 중 실제 졸음인 비율 (오탐지 감소).
    * **재현율 (Recall):** 실제 졸음 상태 중 졸음으로 올바르게 감지한 비율 (미탐지 감소).
    * **F1-Score:** 정밀도와 재현율의 조화 평균.
    * **실시간 처리 속도:** 초당 처리할 수 있는 프레임 수. (모바일 환경에서 30 FPS 이상 권장)
    * **자원 효율성:** Colab 환경에서 GPU/RAM 사용량, 모델 크기 등을 통해 평가됩니다.
* **개인 맞춤형 시스템 평가:** 오탐지(False Positive, 불필요한 경고) 및 미탐지(False Negative, 졸음을 감지하지 못함)율의 감소를 중요한 지표로 평가합니다. 특히 운전자별로 이 지표가 얼마나 개선되는지를 중점적으로 확인합니다.

### 8. 추후 발전 방향

* **다중 모달 데이터 융합:**
    * 카메라 기반 시각 정보(눈, 입, 고개 움직임) 외에 운전 패턴(차선 이탈, 흔들림), 음성(하품 소리), 심박수 등 추가적인 생체 신호(저비용 센서 활용)를 통합하여 졸음 감지의 정확도와 신뢰성을 높입니다.
* **강건성 및 일반화 향상:**
    * 다양한 조명 조건(야간, 역광 등), 안경 착용, 마스크 착용 등 현실적인 운전 환경에서의 모델 강건성을 확보하기 위한 데이터셋 확장 및 모델 최적화가 필요합니다.
    * 다양한 인종, 연령, 성별의 운전자 데이터를 추가하여 모델의 일반화 성능을 개선합니다.
* **경고 및 피드백 시스템 고도화:**
    * 단순 경고음 외에 시각적 알림, 진동 시트, 커피점 추천 등 운전자의 졸음을 효과적으로 해소하고 안전운전을 유도할 수 있는 다양한 형태의 경고 및 피드백 메커니즘을 개발합니다.
* **피로도 예측 및 사전 예방:**
    * 단순 졸음 감지를 넘어, 운전자의 피로도를 지속적으로 모니터링하고 학습하여 졸음이 발생하기 전에 미리 경고하는 예측 시스템으로 발전시킬 수 있습니다.
